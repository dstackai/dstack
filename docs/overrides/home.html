{% extends "main.html" %}

{% block scripts %}
{{ super() }}
<script>
    window.$crisp = [];
    window.CRISP_WEBSITE_ID = "ce56e3b2-a23e-4d3f-9e80-e08c61a2b3cb";
    (function () {
        let d = document;
        let s = d.createElement("script");
        s.src = "https://client.crisp.chat/l.js";
        s.async = 1;
        d.getElementsByTagName("head")[0].appendChild(s);
        $crisp.push(["do", "chat:hide"]);
    })();
</script>
<script type="text/javascript">
    /*
        new Termynal('#vscode-command-example',
            {
                lineData: [
                    {type: 'input', value: 'dstack run .'},
                    {delay: 0, value: ' ', class: 'newline'},
                    {
                        delay: 0,
                        value: 'RUN                 USER   INSTANCE       RESOURCES                 SPOT',
                        class: 'newline'
                    },
                    {
                        delay: 0,
                        value: 'honest-jellyfish-1  peter  a2-highgpu-1g  12xCPUs, 87040MB, 1xA100  yes',
                        class: 'newline'
                    },
                    {delay: 0, value: ' ', class: 'newline'},
                    {delay: 0, startDelay: 0, lineDelay: 0, value: 'Continue? ', class: 'no-newline'},
                    {
                        type: 'input',
                        startDelay: 0,
                        lineDelay: 0,
                        typeDelay: 1000,
                        prompt: '[y/n]',
                        value: 'y',
                        class: 'no-newline'
                    },
                    {delay: 0, value: ' ', class: 'newline'},
                    {delay: 0, value: 'Provisioning and starting a tunnel...', class: 'newline'},
                    {type: 'progress', progressPercent: 100},
                    {delay: 0, value: ' ', class: 'newline'},
                    {delay: 0, value: 'To open in VS Code Desktop, use this link:', class: 'newline'},
                    {delay: 0, value: '  vscode://vscode-remote/ssh-remote+turtle-11/workflow', class: 'newline'},
                    {delay: 0, value: ' ', class: 'newline'},
                    {delay: 0, value: 'To exit, press Ctrl+C.\n', class: 'no-newline'},
                ]
            }
        );
    */
    new Termynal('#train-command-example',
        {
            lineData: [
                {type: 'input', value: 'dstack run . -f train.dstack.yml'},
                {delay: 0, value: ' ', class: 'newline'},
                {
                    delay: 0,
                    value: 'RUN            USER   INSTANCE       RESOURCES                 SPOT',
                    class: 'newline'
                },
                {
                    delay: 0,
                    value: 'wet-mangust-7  peter  a2-highgpu-1g  12xCPUs, 87040MB, 1xA100  yes',
                    class: 'newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
                {delay: 0, startDelay: 0, lineDelay: 0, value: 'Continue? ', class: 'no-newline'},
                {
                    type: 'input',
                    startDelay: 0,
                    lineDelay: 0,
                    typeDelay: 1000,
                    prompt: '[y/n]',
                    value: 'y',
                    class: 'no-newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
                {delay: 0, value: 'Waiting for capacity... To exit, press Ctrl+C.', class: 'newline'},
                {delay: 5000, value: ' ', class: 'newline'},
                {
                    delay: 5000,
                    value: 'Epoch 0:  100% 1719/1719 [00:18<00:00, 92.32it/s, loss=0.0981, acc=0.969]\n',
                    class: 'newline'
                },
                {
                    delay: 5000,
                    value: 'Epoch 1:  100% 1719/1719 [00:18<00:00, 92.32it/s, loss=0.0981, acc=0.969]\n',
                    class: 'newline'
                },
                {
                    delay: 5000,
                    value: 'Epoch 2:  100% 1719/1719 [00:18<00:00, 92.32it/s, loss=0.0981, acc=0.969]\n',
                    class: 'newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
            ]
        }
    );
    new Termynal('#serve-command-example',
        {
            lineData: [
                {type: 'input', value: 'dstack run . -f serve.dstack.yml'},
                {delay: 0, value: ' ', class: 'newline'},
                {
                    delay: 0,
                    value: 'RUN           USER   INSTANCE       RESOURCES                 SPOT',
                    class: 'newline'
                },
                {
                    delay: 0,
                    value: 'mean-snail-1  peter  a2-highgpu-1g  12xCPUs, 87040MB, 1xA100  yes',
                    class: 'newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
                {delay: 0, startDelay: 0, lineDelay: 0, value: 'Continue? ', class: 'no-newline'},
                {
                    type: 'input',
                    startDelay: 0,
                    lineDelay: 0,
                    typeDelay: 1000,
                    prompt: '[y/n]',
                    value: 'y',
                    class: 'no-newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
                {delay: 0, value: 'Provisioning and starting a tunnel...', class: 'newline'},
                {type: 'progress', progressPercent: 100},
                {delay: 0, value: ' ', class: 'newline'},
                {
                    delay: 0,
                    value: 'Running on local URL:  http://127.0.0.1:7860',
                    class: 'newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
                {
                    delay: 0,
                    value: 'To stop, press Ctrl+C.',
                    class: 'newline'
                },
                {delay: 0, value: ' ', class: 'newline'},
            ]
        }
    );
</script>
{% endblock %}

{% block content %}
<section class="tx-container">
    <div class="md-grid md-typeset">
        <div class="tx-landing__hero">
            <div class="tx-landing__hero_text">
                <h1>Cost-effective LLM development</h1>
                <p><strong>dstack</strong> is an open-source tool that simplifies LLM development across multiple
                    clouds.
                </p>

                <p>It streamlines development and deployment, reduces cloud costs, and frees users from vendor lock-in.
                </p>

                <a href="/docs" class="md-button md-button--primary">
                    Get started</a>

                <a href="https://join.slack.com/t/dstackai/shared_invite/zt-xdnsytie-D4qU9BvJP8vkbkHXdi6clQ"
                   target="_blank" class="md-button md-button-secondary slack">Join Slack</a>
            </div>

            <div class="tx-landing__hero_image">
                <img src="assets/images/hero.svg" style="max-width:800px; width:100%"/>
            </div>
        </div>

        <div class="tx-landing__integrations">
            <div class="tx-landing__integrations_text">
                <h2>Switch between clouds to cut costs</h2>
            </div>
            <div class="tx-landing__integrations_logos">
                <img class="logo-xlarge" src="assets/images/aws-logo.svg" title="Amazon Web Services">
                <img class="logo-large" src="assets/images/gcp-logo.svg" title="Google Cloud Platform">
                <img class="logo-large" src="assets/images/azure-logo.svg" title="Microsoft Azure">
                <img class="logo-large" src="assets/images/lambda-logo.svg" title="Lambda Cloud">
            </div>
        </div>

        <div class="tx-landing__major_feature">
            <div class="section">
                <div class="block margin">
                    <div>
                        <h2>Dev environments</h2>
                        <p>Configure the hardware <strong>resources</strong> you need (GPU, memory, etc.) and
                            indicate whether you want to use <strong>spot</strong> or <strong>on-demand</strong>
                            instances.</p>

                        <p><strong>dstack</strong> will automatically provision cloud resources,
                            and forward <strong>ports</strong> for secure and convenient access.</p>

                        <p>Access the cloud dev environment conveniently using your local <strong>desktop</strong> IDE.
                        </p>
                    </div>
                </div>

                <div class="block large">
                    <img src="assets/images/dstack-vscode-jupyter.png" alt="">
                </div>
            </div>
        </div>

        <div class="tx-landing__major_feature">
            <div class="section">
                <div class="block large margin">
                    <div id="serve-command-example" data-termynal>
                    </div>
                </div>
                <div class="block">
                    <div>
                        <h2>Serving</h2>
                        <p>Serve models using <strong>Gradio</strong>, <strong>Streamlit</strong>,
                            <strong>FastAPI</strong>, <strong>vLLM</strong>, <strong>TGI</strong>, and
                            other frameworks in any cloud.
                        </p>

                        <p>Configure the hardware <strong>resources</strong> you need (GPU, memory, etc.) and
                            indicate whether you want to use <strong>spot</strong> or <strong>on-demand</strong>
                            instances.</p>

                        <p><strong>dstack</strong> will automatically provision cloud resources,
                            and forward <strong>ports</strong> for secure and convenient access.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="tx-landing__major_feature">
            <div class="section">
                <div class="block margin">
                    <div>
                        <h2>Training</h2>
                        <p><strong>Pre-train</strong> and <strong>finetune</strong> your own state-of-the-art models
                            easily and
                            cost-effectively in any cloud.</p>

                        <p>Configure the hardware <strong>resources</strong> you need (GPU, memory, etc.) and
                            indicate whether you want to use <strong>spot</strong> or <strong>on-demand</strong>
                            instances.</p>

                        <p>Access and manage your <strong>data</strong> and <strong>artifacts</strong> using
                            the built-in Python SDK.</p>
                    </div>
                </div>

                <div class="block large">
                    <div id="train-command-example" data-termynal>
                    </div>
                </div>
            </div>
        </div>

        <div class="-landing__highlights">
            <div class="tx-landing__highlights_text">
                <h2>Featured examples</h2>
            </div>

            <div class="tx-landing__highlights_grid">
                <a href="examples/finetuning-llama-2">
                    <div class="feature-cell">
                        <div class="feature-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M3 17v2h6v-2H3M3 5v2h10V5H3m10 16v-2h8v-2h-8v-2h-2v6h2M7 9v2H3v2h4v2h2V9H7m14 4v-2H11v2h10m-6-4h2V7h4V5h-4V3h-2v6Z"></path>
                            </svg>
                        </div>
                        <h3>
                            Fine-tuning Llama 2
                        </h3>

                        <p>
                            Fine-tuning <strong>Llama 2</strong> on a custom dataset using the <strong>peft</strong>,
                            and
                            <strong>bitsandbytes</strong>, and <strong>trl</strong> libraries.
                        </p>
                    </div>
                </a>

                <a href="examples/stable-diffusion-xl">
                    <div class="feature-cell">
                        <div class="feature-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M17.5 12a1.5 1.5 0 0 1-1.5-1.5A1.5 1.5 0 0 1 17.5 9a1.5 1.5 0 0 1 1.5 1.5 1.5 1.5 0 0 1-1.5 1.5m-3-4A1.5 1.5 0 0 1 13 6.5 1.5 1.5 0 0 1 14.5 5 1.5 1.5 0 0 1 16 6.5 1.5 1.5 0 0 1 14.5 8m-5 0A1.5 1.5 0 0 1 8 6.5 1.5 1.5 0 0 1 9.5 5 1.5 1.5 0 0 1 11 6.5 1.5 1.5 0 0 1 9.5 8m-3 4A1.5 1.5 0 0 1 5 10.5 1.5 1.5 0 0 1 6.5 9 1.5 1.5 0 0 1 8 10.5 1.5 1.5 0 0 1 6.5 12M12 3a9 9 0 0 0-9 9 9 9 0 0 0 9 9 1.5 1.5 0 0 0 1.5-1.5c0-.39-.15-.74-.39-1-.23-.27-.38-.62-.38-1a1.5 1.5 0 0 1 1.5-1.5H16a5 5 0 0 0 5-5c0-4.42-4.03-8-9-8Z"></path>
                            </svg>
                        </div>
                        <h3>
                            Serving SDXL with FastAPI
                        </h3>

                        <p>
                            Serving <strong>Stable Diffusion XL</strong> with <strong>FastAPI</strong> to generate
                            and refine images via a REST endpoint.
                        </p>
                    </div>
                </a>

                <a href="examples/vllm">
                    <div class="feature-cell">
                        <div class="feature-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="-3 -3 27 27">
                                <path d="m13.13 22.19-1.63-3.83c1.57-.58 3.04-1.36 4.4-2.27l-2.77 6.1M5.64 12.5l-3.83-1.63 6.1-2.77C7 9.46 6.22 10.93 5.64 12.5M21.61 2.39S16.66.269 11 5.93c-2.19 2.19-3.5 4.6-4.35 6.71-.28.75-.09 1.57.46 2.13l2.13 2.12c.55.56 1.37.74 2.12.46A19.1 19.1 0 0 0 18.07 13c5.66-5.66 3.54-10.61 3.54-10.61m-7.07 7.07c-.78-.78-.78-2.05 0-2.83s2.05-.78 2.83 0c.77.78.78 2.05 0 2.83-.78.78-2.05.78-2.83 0m-5.66 7.07-1.41-1.41 1.41 1.41M6.24 22l3.64-3.64c-.34-.09-.67-.24-.97-.45L4.83 22h1.41M2 22h1.41l4.77-4.76-1.42-1.41L2 20.59V22m0-2.83 4.09-4.08c-.21-.3-.36-.62-.45-.97L2 17.76v1.41Z"></path>
                            </svg>
                        </div>
                        <h3>
                            Serving LLMs with vLLM
                        </h3>

                        <p>
                            Serve open-source LLMs as OpenAI-compatible APIs with up to 24 times higher throughput using
                            the <strong>vLLM</strong> library.
                        </p>
                    </div>
                </a>

                <a href="examples/text-generation-inference">
                    <div class="feature-cell">
                        <div class="feature-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16 9h3l-5 7m-4-7h4l-2 8M5 9h3l2 7m5-12h2l2 3h-3m-5-3h2l1 3h-4M7 4h2L8 7H5m1-5L2 8l10 14L22 8l-4-6H6Z"></path>
                            </svg>
                        </div>
                        <h3>
                            Serving LLMs with TGI
                        </h3>

                        <p>
                            Serve open-source LLMs as APIs with optimized performance using <strong>TGI</strong>, an
                            open-source tool by
                            Hugging Face.
                        </p>
                    </div>
                </a>

                <a href="examples/llmchat">
                    <div class="feature-cell">
                        <div class="feature-icon">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M12 3c5.5 0 10 3.58 10 8s-4.5 8-10 8c-1.24 0-2.43-.18-3.53-.5C5.55 21 2 21 2 21c2.33-2.33 2.7-3.9 2.75-4.5C3.05 15.07 2 13.13 2 11c0-4.42 4.5-8 10-8m5 9v-2h-2v2h2m-4 0v-2h-2v2h2m-4 0v-2H7v2h2Z"></path>
                            </svg>
                        </div>
                        <h3>
                            LLM as Chatbot
                        </h3>

                        <p>
                            Run an open-source LLM of your choice, either as a <strong>Gradio</strong> app or as a
                            <strong>Discord</strong> bot, with internet search capability.
                        </p>
                    </div>
                </a>
            </div>
        </div>

        <div class="tx-landing__bottom_cta">
            <div>
                <h2>Get started in less than a minute</h2>
                <div class="termy">
                    <pre class="highlight">
$ pip install "dstack[aws,gcp,azure,lambda]"
$ dstack start
                    </pre>
                </div>
                <p class="tx-landing__bottom_cta_text">
                    And you're <strong>done</strong>! Now you can run dev environments and tasks
                    both <strong>locally</strong> and in <strong>your cloud</strong>.
                </p>

                <a href="/docs" class="md-button md-button--primary">
                    Get started</a>

                <a href="https://join.slack.com/t/dstackai/shared_invite/zt-xdnsytie-D4qU9BvJP8vkbkHXdi6clQ"
                   target="_blank" class="md-button md-button-secondary slack">Join Slack</a>
            </div>
        </div>
    </div>
</section>
{% endblock %}