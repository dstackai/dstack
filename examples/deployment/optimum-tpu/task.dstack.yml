type: task
# The name is optional, if not specified, generated randomly
name: llama31-task-optimum-tpu

# Using a Docker image with a fix instead of the official one
# More details at https://github.com/huggingface/optimum-tpu/pull/87
image: sjbbihan/optimum-tpu:latest
# Required environment variables
env:
  - HUGGING_FACE_HUB_TOKEN
  - MODEL_ID=meta-llama/Meta-Llama-3.1-8B-Instruct
  - MAX_TOTAL_TOKENS=4096
  - MAX_BATCH_PREFILL_TOKENS=4095
commands:
  - text-generation-launcher --port 8000
ports: [8000]

resources:
  # Required resources
  gpu: v5litepod-4

# Use either spot or on-demand instances
spot_policy: auto