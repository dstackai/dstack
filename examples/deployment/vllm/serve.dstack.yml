type: service
# This service runs Llama 2 with vllm

image: vllm/vllm-openai:latest
env:
  - MODEL=NousResearch/Llama-2-7b-chat-hf
  - PYTHONPATH=/workspace
commands:
  - python3 -m vllm.entrypoints.openai.api_server --model $MODEL --port 8000
port: 8000

resources:
  gpu: 24GB

# (Optional) Enable the OpenAI-compatible endpoint
model:
  format: openai
  type: chat
  name: NousResearch/Llama-2-7b-chat-hf
