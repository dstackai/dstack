type: task
# The name is optional, if not specified, generated randomly
name: llama31-task-tgi

# The official TGI Docker image
image: ghcr.io/huggingface/text-generation-inference:latest

# Required environment variables
env:
  - HUGGING_FACE_HUB_TOKEN
  - MODEL_ID=meta-llama/Meta-Llama-3.1-8B-Instruct
  - MAX_INPUT_LENGTH=4000
  - MAX_TOTAL_TOKENS=4096
commands:
  - NUM_SHARD=$DSTACK_GPUS_NUM text-generation-launcher
ports: [80]

# Use either spot or on-demand instances
spot_policy: auto

resources:
  # Required resources
  gpu: 24GB
  # Shared memory (required by multi-gpu)
  shm_size: 24GB