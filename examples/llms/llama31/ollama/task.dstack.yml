type: task
name: llama31-task-ollama

image: ollama/ollama
commands:
  - ollama serve &
  - sleep 3
  - ollama pull llama3.1
  - fg
ports:
  - 11434

# Use either spot or on-demand instances
spot_policy: auto

# Required resources
resources:
  gpu: 24GB