type: task
name: chat-ui-task

docker: true
env:
  - MODEL_ID=meta-llama/Llama-3.2-3B-Instruct
  - HF_TOKEN
files:
  - compose.yaml
commands:
  - docker compose up
ports:
  - 9000

# Use either spot or on-demand instances
spot_policy: auto

resources:
  gpu: 1

# Cache the Docker data
volumes:
  - instance_path: /root/.cache/docker-data
    path: /var/lib/docker
    optional: true
