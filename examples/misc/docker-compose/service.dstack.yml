type: service
name: chat-ui-service

docker: true
env:
  - MODEL_ID=meta-llama/Llama-3.2-3B-Instruct
  - HF_TOKEN
files:
  - compose.yaml
commands:
  - docker compose up
port: 9000
auth: false

# Uncomment to leverage spot instances
#spot_policy: auto

resources:
  # Required resources
  gpu: 1

# Cache the Docker data
volumes:
  - instance_path: /root/.cache/docker-data
    path: /var/lib/docker
    optional: true
